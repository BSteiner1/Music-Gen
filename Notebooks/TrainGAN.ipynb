{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHt2ZHaLXDaUNWhS2E+H0K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BSteiner1/Music-Gen/blob/main/Notebooks/TrainGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itCpNHmj1Fet",
        "outputId": "e74db507-80b5-42c6-bb16-ce36d2790e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Music-Gen'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 103 (delta 42), reused 86 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (103/103), 657.94 KiB | 2.71 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BSteiner1/Music-Gen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "1JC9qx3n2JdL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "%cd /content/Music-Gen\n",
        "from utils.ExtractData import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTx5vaCg1Hi_",
        "outputId": "1ba0154e-b062-452c-918d-0034f2a7fb5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Music-Gen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/DoodleSample'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYSHAO_K1NMy",
        "outputId": "0dc90e1d-baca-4636-ef81-90211eba584d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_data = get_cleaned_phrases(path, 1000)"
      ],
      "metadata": {
        "id": "rJREBSAK2VSo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [torch.Tensor(array) for array in array_data]"
      ],
      "metadata": {
        "id": "0ix1liOr1VYf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(*data)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "Gd7Bcy-m_Xc2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Generator and Discriminator networks\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(Generator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        seq_length = x.size(1)  # Get the sequence length\n",
        "\n",
        "        # Initialize the hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # Apply sigmoid activation to squash the values between 0 and 1\n",
        "        out = torch.sigmoid(out) * 128  # Scale to the range [0, 128]\n",
        "\n",
        "        return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class LSTMGAN(nn.Module):\n",
        "    def __init__(self, input_dim, generator_input_dim, discriminator_input_dim, hidden_dim, num_layers):\n",
        "        super(LSTMGAN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.generator = Generator(generator_input_dim, hidden_dim, input_dim, num_layers)\n",
        "        self.discriminator = Discriminator(discriminator_input_dim, hidden_dim, 1, num_layers)\n",
        "\n",
        "    def train(self, data_loader, epochs, batch_size):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(device)\n",
        "        self.generator.to(device)\n",
        "        self.discriminator.to(device)\n",
        "\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.001)\n",
        "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.001)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for batch in data_loader:  # Iterate through the DataLoader\n",
        "                real_data = batch.to(device)\n",
        "\n",
        "                batch_size = real_data.size(0)  # Get the batch size\n",
        "                real_labels = torch.ones(batch_size, 1).long().to(device)  # Change to LongTensor\n",
        "                fake_labels = torch.zeros(batch_size, 1).long().to(device)  # Change to LongTensor\n",
        "\n",
        "                d_optimizer.zero_grad()\n",
        "                real_labels = torch.ones(batch_size, 1).long().to(device)  # Change to LongTensor\n",
        "                fake_labels = torch.zeros(batch_size, 1).long().to(device)  # Change to LongTensor\n",
        "\n",
        "                noise = torch.randn(batch_size, 4, generator_input_dim).to(device)\n",
        "                fake_data = self.generator(noise)\n",
        "\n",
        "                #print(real_data.shape)\n",
        "\n",
        "                real_data = real_data.view(batch_size, 4, input_dim)\n",
        "                real_outputs = self.discriminator(real_data)\n",
        "\n",
        "                fake_outputs = self.discriminator(fake_data.detach())\n",
        "\n",
        "                # Reshape both real and fake outputs\n",
        "                real_outputs = real_outputs.view(batch_size, -1)  # Reshape to (batch_size, 2560)\n",
        "                fake_outputs = fake_outputs.view(batch_size, -1)  # Reshape to (batch_size, 2560)\n",
        "\n",
        "                #print(real_outputs)\n",
        "                #print(fake_outputs)\n",
        "\n",
        "                # Apply softmax activation to real and fake outputs\n",
        "                #real_outputs_softmax = torch.softmax(real_outputs, dim=-1)\n",
        "                #fake_outputs_softmax = torch.softmax(fake_outputs, dim=-1)\n",
        "\n",
        "                # Compute CrossEntropyLoss\n",
        "                d_real_loss = criterion(real_outputs, real_labels.float())\n",
        "                d_fake_loss = criterion(fake_outputs, fake_labels.float())\n",
        "\n",
        "                d_loss = d_real_loss + d_fake_loss\n",
        "                d_loss.backward()\n",
        "                d_optimizer.step()\n",
        "\n",
        "                # Inside your training loop\n",
        "                g_optimizer.zero_grad()\n",
        "                noise = torch.randn(batch_size, 4, generator_input_dim).to(device)\n",
        "                fake_data = self.generator(noise)\n",
        "                fake_data = fake_data.view(batch_size, 4, input_dim)\n",
        "                fake_outputs = self.discriminator(fake_data)\n",
        "\n",
        "                # Reshape fake_outputs\n",
        "                fake_outputs = fake_outputs.view(batch_size, -1)  # Reshape to (batch_size, 2560)\n",
        "\n",
        "                #print(\"hi\")\n",
        "\n",
        "                g_loss = criterion(fake_outputs, fake_labels.float())  # Use flattened data\n",
        "                #print(\"done)\")\n",
        "                g_loss.backward()\n",
        "                g_optimizer.step()\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n"
      ],
      "metadata": {
        "id": "AZ0oS0Xr6bug"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader directly from the list of tensors\n",
        "batch_size = 20\n",
        "dataset = TensorDataset(*data)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "# Define the Generator and Discriminator networks\n",
        "# ... (Your Generator and Discriminator class definitions)\n",
        "\n",
        "# Instantiate the GAN\n",
        "input_dim = 32  # Number of features in each sequence\n",
        "generator_input_dim = 32  # Input dimension for the generator (number of notes)\n",
        "discriminator_input_dim = 32  # Input dimension for the discriminator (number of notes)\n",
        "hidden_dim = 64\n",
        "num_layers = 2\n",
        "gan = LSTMGAN(input_dim, generator_input_dim, discriminator_input_dim, hidden_dim, num_layers)\n",
        "\n",
        "# Train the GAN using the DataLoader\n",
        "epochs = 10\n",
        "gan.train(data_loader, epochs, batch_size = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koVrHvThBc8F",
        "outputId": "23ac98d5-d1a2-4a49-d733-8f4e0b11c657"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, D Loss: 1.002524971961975, G Loss: 0.5440442562103271\n",
            "Epoch 2/10, D Loss: 0.12233742326498032, G Loss: 0.07987654954195023\n",
            "Epoch 3/10, D Loss: 0.018833357840776443, G Loss: 0.01192763913422823\n",
            "Epoch 4/10, D Loss: 0.009176447987556458, G Loss: 0.005569863598793745\n",
            "Epoch 5/10, D Loss: 0.006349492818117142, G Loss: 0.003788155736401677\n",
            "Epoch 6/10, D Loss: 0.004915283527225256, G Loss: 0.0028864534106105566\n",
            "Epoch 7/10, D Loss: 0.003915386740118265, G Loss: 0.0022327350452542305\n",
            "Epoch 8/10, D Loss: 0.0031801071017980576, G Loss: 0.0017726199002936482\n",
            "Epoch 9/10, D Loss: 0.002657230943441391, G Loss: 0.0014605213655158877\n",
            "Epoch 10/10, D Loss: 0.002278430387377739, G Loss: 0.001235967967659235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7coOs2qnAfJB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}